import * as pulumi from "@pulumi/pulumi"
import * as aws from "@pulumi/aws"

import * as fs from "fs"
import * as mime from "mime"
import * as path from "path"



export const bucketName = bucket.id
export const publicUrl = bucket.websiteEndpoint

function toPage(title: string, content: string) {
    return `<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>${title}</title>
    <link rel="stylesheet" href="/main.css">
</head>
<body>
    ${content}
</body>
</html>`
}

// crawlDirectory recursive crawls the provided directory, applying the provided function
// to every file it contains. Doesn't handle cycles from symlinks.
function crawlDirectory(dir: string, f: (_: string) => void) {
    const files = fs.readdirSync(dir)

    for (const file of files) {
        const filePath = `${dir}/${file}`
        const stat = fs.statSync(filePath)

        if (stat.isDirectory()) {
            crawlDirectory(filePath, f)
        }

        if (stat.isFile()) {
            f(filePath)
        }
    }
}
